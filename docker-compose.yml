version: "3.9"

services:
  airflow-webserver:
    image: apache/airflow:2.8.1-python3.11
    container_name: airflow-webserver
    env_file:
      - ./env/airflow.env
    environment:
      PIP_ADDITIONAL_REQUIREMENTS: "-r /opt/airflow/src/requirements.txt"
    ports:
      - "8080:8080"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./src:/opt/airflow/src
      - ./infra/airflow/logs:/opt/airflow/logs
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./data/raw:/opt/airflow/raw
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
    command: >
      bash -c "pip install --no-cache-dir -r /opt/airflow/src/requirements.txt && exec airflow webserver"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  airflow-scheduler:
    image: apache/airflow:2.8.1-python3.11
    container_name: airflow-scheduler
    env_file:
      - ./env/airflow.env
    environment:
      PIP_ADDITIONAL_REQUIREMENTS: "-r /opt/airflow/src/requirements.txt"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./src:/opt/airflow/src
      - ./infra/airflow/logs:/opt/airflow/logs
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./data/raw:/opt/airflow/raw
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
    command: >
      bash -c "pip install --no-cache-dir -r /opt/airflow/src/requirements.txt && exec airflow scheduler"
    depends_on:
      airflow-webserver:
        condition: service_started
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  airflow-triggerer:
    image: apache/airflow:2.8.1-python3.11
    container_name: airflow-triggerer
    env_file:
      - ./env/airflow.env
    environment:
      PIP_ADDITIONAL_REQUIREMENTS: "-r /opt/airflow/src/requirements.txt"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./src:/opt/airflow/src
      - ./infra/airflow/logs:/opt/airflow/logs
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./data/raw:/opt/airflow/raw
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
    command: >
      bash -c "pip install --no-cache-dir -r /opt/airflow/src/requirements.txt && exec airflow triggerer"
    depends_on:
      airflow-webserver:
        condition: service_started
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  airflow-worker:
    image: apache/airflow:2.8.1-python3.11
    container_name: airflow-worker
    env_file:
      - ./env/airflow.env
    environment:
      PIP_ADDITIONAL_REQUIREMENTS: "-r /opt/airflow/src/requirements.txt"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./src:/opt/airflow/src
      - ./infra/airflow/logs:/opt/airflow/logs
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./data/raw:/opt/airflow/raw
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
    command: >
      bash -c "pip install --no-cache-dir -r /opt/airflow/src/requirements.txt && exec airflow celery worker --concurrency 4"
    depends_on:
      airflow-webserver:
        condition: service_started
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  airflow-init:
    image: apache/airflow:2.8.1-python3.11
    container_name: airflow-init
    env_file:
      - ./env/airflow.env
    environment:
      PIP_ADDITIONAL_REQUIREMENTS: "-r /opt/airflow/src/requirements.txt"
    entrypoint: /bin/bash
    command: >
      bash -c "pip install --no-cache-dir -r /opt/airflow/src/requirements.txt && \
      airflow db init && \
      airflow users create --username \"$${AIRFLOW_ADMIN_USER:-admin}\" \
        --firstname Admin --lastname User --role Admin \
        --email \"$${AIRFLOW_ADMIN_EMAIL:-admin@example.com}\" \
        --password \"$${AIRFLOW_ADMIN_PASSWORD:-admin}\""
    volumes:
      - ./dags:/opt/airflow/dags
      - ./dbt:/opt/airflow/dbt
      - ./src:/opt/airflow/src
      - ./infra/airflow/logs:/opt/airflow/logs
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./data/raw:/opt/airflow/raw
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_started

  dbt-runner:
    image: ghcr.io/dbt-labs/dbt-postgres:1.7.11
    container_name: dbt-runner
    env_file:
      - ./env/dbt.env
    volumes:
      - ./dbt:/usr/app/dbt
    entrypoint: ["/bin/sh", "-c", "sleep infinity"]

  dbt-docs:
    image: ghcr.io/dbt-labs/dbt-postgres:1.7.11
    container_name: dbt-docs
    env_file:
      - ./env/dbt.env
    ports:
      - "8081:8081"
    volumes:
      - ./dbt:/usr/app/dbt
    command: >
      /bin/sh -c "dbt deps && dbt docs generate && dbt docs serve --host 0.0.0.0 --port 8081"
    depends_on:
      - postgres

  n8n:
    image: n8nio/n8n:latest
    container_name: n8n
    env_file:
      - ./env/n8n.env
    ports:
      - "5678:5678"
    volumes:
      - ./infra/n8n/data:/home/node/.n8n

  metabase:
    image: metabase/metabase:v0.49.14
    container_name: metabase
    env_file:
      - ./env/metabase.env
    ports:
      - "3000:3000"
    volumes:
      - ./infra/metabase/data:/metabase-data
    depends_on:
      - postgres

  postgres:
    image: postgres:15-alpine
    container_name: airflow-postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: ${AIRFLOW_DB_PASSWORD:-airflow}
      POSTGRES_DB: airflow
    ports:
      - "55432:5432"
    volumes:
      - ./infra/postgres/data:/var/lib/postgresql/data
      - ./infra/postgres/init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s

  redis:
    image: redis:7-alpine
    container_name: airflow-redis
    command: redis-server --save "" --appendonly no
